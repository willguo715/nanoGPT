# nanoGPT

ä¸€ä¸ªç®€æ´ã€é«˜æ•ˆçš„ GPT æ¨¡å‹å®ç°ï¼Œç”¨äºè®­ç»ƒå’Œå¾®è°ƒè¯­è¨€æ¨¡å‹ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸš€ **ç®€æ´å®ç°**ï¼šæ ¸å¿ƒä»£ç æ¸…æ™°æ˜“æ‡‚ï¼Œé€‚åˆå­¦ä¹ å’Œç ”ç©¶
- ğŸ“š **å­—ç¬¦çº§è®­ç»ƒ**ï¼šæ”¯æŒå­—ç¬¦çº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆ
- âš¡ **é«˜æ•ˆè®­ç»ƒ**ï¼šæ”¯æŒ PyTorch 2.0 ç¼–è¯‘åŠ é€Ÿï¼ˆéœ€è¦ CUDAï¼‰
- ğŸ”§ **çµæ´»é…ç½®**ï¼šæ”¯æŒé…ç½®æ–‡ä»¶æˆ–å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
- ğŸ’¾ **æ£€æŸ¥ç‚¹ä¿å­˜**ï¼šè‡ªåŠ¨ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹ï¼Œæ”¯æŒæ–­ç‚¹ç»­è®­
- ğŸ“Š **å¯é€‰æ—¥å¿—**ï¼šæ”¯æŒ wandb è®­ç»ƒæ—¥å¿—ï¼ˆå¯é€‰ï¼‰

## å®‰è£…

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 2.0.0+
- CUDAï¼ˆå¯é€‰ï¼Œç”¨äº GPU è®­ç»ƒï¼‰

### å®‰è£…æ­¥éª¤

1. å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®

2. å®‰è£…ä¾èµ–ï¼š
```bash
pip install -r requirements.txt
```

3. å‡†å¤‡æ•°æ®é›†ï¼ˆä»¥ Shakespeare æ•°æ®é›†ä¸ºä¾‹ï¼‰ï¼š
```bash
cd data/shakespeare_char
python prepare.py
```

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬è®­ç»ƒ

ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒï¼š
```bash
python train.py
```

ä½¿ç”¨é…ç½®æ–‡ä»¶è®­ç»ƒï¼š
```bash
python train.py config/train_shakespeare_char.py
```

### å‘½ä»¤è¡Œå‚æ•°è¦†ç›–

å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®ï¼š
```bash
python train.py config/train_shakespeare_char.py --batch_size=32 --learning_rate=1e-4
```

### é…ç½®æ–‡ä»¶æ ¼å¼

é…ç½®æ–‡ä»¶æ˜¯ Python æ–‡ä»¶ï¼ŒåŒ…å«è®­ç»ƒå‚æ•°ï¼š

```python
# è¾“å‡ºç›®å½•
out_dir = 'out-shakespeare-char'

# æ•°æ®é›†
dataset = 'shakespeare_char'
batch_size = 64
block_size = 256

# æ¨¡å‹é…ç½®
n_layer = 6
n_head = 6
n_embd = 384
dropout = 0.2

# è®­ç»ƒé…ç½®
learning_rate = 1e-3
max_iters = 5000
```

## ä¸»è¦é…ç½®å‚æ•°

### æ•°æ®é›†ç›¸å…³
- `dataset`: æ•°æ®é›†åç§°ï¼ˆå¯¹åº” `data/` ç›®å½•ä¸‹çš„æ–‡ä»¶å¤¹ï¼‰
- `batch_size`: æ‰¹æ¬¡å¤§å°
- `block_size`: ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆåºåˆ—é•¿åº¦ï¼‰

### æ¨¡å‹ç›¸å…³
- `n_layer`: Transformer å±‚æ•°
- `n_head`: æ³¨æ„åŠ›å¤´æ•°
- `n_embd`: åµŒå…¥ç»´åº¦
- `dropout`: Dropout æ¯”ç‡
- `bias`: æ˜¯å¦ä½¿ç”¨åç½®ï¼ˆé»˜è®¤ Falseï¼‰

### è®­ç»ƒç›¸å…³
- `learning_rate`: å­¦ä¹ ç‡
- `max_iters`: æœ€å¤§è®­ç»ƒè¿­ä»£æ¬¡æ•°
- `warmup_iters`: å­¦ä¹ ç‡é¢„çƒ­æ­¥æ•°
- `lr_decay_iters`: å­¦ä¹ ç‡è¡°å‡æ­¥æ•°
- `min_lr`: æœ€å°å­¦ä¹ ç‡
- `weight_decay`: æƒé‡è¡°å‡
- `beta1`, `beta2`: AdamW ä¼˜åŒ–å™¨çš„åŠ¨é‡å‚æ•°
- `grad_clip`: æ¢¯åº¦è£å‰ªé˜ˆå€¼

### ç³»ç»Ÿç›¸å…³
- `device`: è®¾å¤‡ç±»å‹ï¼ˆ'cuda' æˆ– 'cpu'ï¼‰
- `dtype`: æ•°æ®ç±»å‹ï¼ˆ'float32', 'bfloat16', 'float16'ï¼‰
- `compile`: æ˜¯å¦ä½¿ç”¨ PyTorch 2.0 ç¼–è¯‘ï¼ˆCPU æ¨¡å¼ä¸‹éœ€è¦ C++ ç¼–è¯‘å™¨ï¼‰

## æ³¨æ„äº‹é¡¹

### CPU è®­ç»ƒ
- åœ¨ CPU æ¨¡å¼ä¸‹ï¼Œ`torch.compile` ä¼šè‡ªåŠ¨ç¦ç”¨ï¼ˆéœ€è¦ C++ ç¼–è¯‘å™¨ï¼‰
- å¦‚éœ€å¯ç”¨ç¼–è¯‘ï¼Œè¯·å®‰è£… Visual Studio Build Toolsï¼ˆWindowsï¼‰æˆ– GCC/Clangï¼ˆLinux/Macï¼‰

### æ£€æŸ¥ç‚¹
- æ£€æŸ¥ç‚¹ä¿å­˜åœ¨ `out_dir` ç›®å½•ä¸‹
- ä½¿ç”¨ `init_from = 'resume'` å¯ä»¥ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ

### åˆ†å¸ƒå¼è®­ç»ƒ
- æ”¯æŒå¤š GPU åˆ†å¸ƒå¼è®­ç»ƒï¼ˆDDPï¼‰
- ä½¿ç”¨ç¯å¢ƒå˜é‡ `RANK`, `LOCAL_RANK`, `WORLD_SIZE` é…ç½®

## é¡¹ç›®ç»“æ„

```
nanoGPT/
â”œâ”€â”€ train.py              # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ model.py              # GPT æ¨¡å‹å®šä¹‰
â”œâ”€â”€ configurator.py       # é…ç½®è§£æå™¨
â”œâ”€â”€ requirements.txt      # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ config/               # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â””â”€â”€ train_shakespeare_char.py
â”œâ”€â”€ data/                 # æ•°æ®é›†ç›®å½•
â”‚   â””â”€â”€ shakespeare_char/
â”‚       â”œâ”€â”€ prepare.py    # æ•°æ®é¢„å¤„ç†è„šæœ¬
â”‚       â”œâ”€â”€ train.bin    # è®­ç»ƒæ•°æ®
â”‚       â””â”€â”€ val.bin      # éªŒè¯æ•°æ®
â””â”€â”€ out/                  # è¾“å‡ºç›®å½•ï¼ˆè®­ç»ƒæ£€æŸ¥ç‚¹ï¼‰
```

## ç¤ºä¾‹

è®­ç»ƒ Shakespeare å­—ç¬¦çº§æ¨¡å‹ï¼š
```bash
python train.py config/train_shakespeare_char.py
```

è®­ç»ƒå®Œæˆåï¼Œæ£€æŸ¥ç‚¹ä¼šä¿å­˜åœ¨ `out-shakespeare-char/ckpt.pt`ã€‚

## è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æºã€‚

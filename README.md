# nanoGPT

ä¸€ä¸ªç®€æ´ã€é«˜æ•ˆçš„ GPT æ¨¡å‹å®ç°ï¼Œç”¨äºè®­ç»ƒå’Œå¾®è°ƒè¯­è¨€æ¨¡å‹ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸš€ **ç®€æ´å®ç°**ï¼šæ ¸å¿ƒä»£ç æ¸…æ™°æ˜“æ‡‚ï¼Œé€‚åˆå­¦ä¹ å’Œç ”ç©¶
- ğŸ“š **å­—ç¬¦çº§è®­ç»ƒ**ï¼šæ”¯æŒå­—ç¬¦çº§åˆ«çš„æ–‡æœ¬ç”Ÿæˆ
- âš¡ **é«˜æ•ˆè®­ç»ƒ**ï¼šæ”¯æŒ PyTorch 2.0 ç¼–è¯‘åŠ é€Ÿï¼ˆéœ€è¦ CUDAï¼‰
- ğŸ”§ **çµæ´»é…ç½®**ï¼šæ”¯æŒé…ç½®æ–‡ä»¶æˆ–å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
- ğŸ’¾ **æ£€æŸ¥ç‚¹ä¿å­˜**ï¼šè‡ªåŠ¨ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹ï¼Œæ”¯æŒæ–­ç‚¹ç»­è®­
- ğŸ“Š **å¯é€‰æ—¥å¿—**ï¼šæ”¯æŒ wandb è®­ç»ƒæ—¥å¿—ï¼ˆå¯é€‰ï¼‰

## å®‰è£…

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 2.0.0+
- CUDAï¼ˆå¯é€‰ï¼Œç”¨äº GPU è®­ç»ƒï¼‰

### å®‰è£…æ­¥éª¤

1. å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®

2. å®‰è£…ä¾èµ–ï¼š
```bash
pip install -r requirements.txt
```

3. å‡†å¤‡æ•°æ®é›†ï¼š

**Shakespeare æ•°æ®é›†ï¼š**
```bash
cd data/shakespeare_char
python prepare.py
cd ../..
```

**ä¸­æ–‡å››å¤§åè‘—æ•°æ®é›†ï¼š**
```bash
cd data/chinese
python prepare.py
cd ../..
```

æ³¨æ„ï¼šä¸­æ–‡æ•°æ®é›†éœ€è¦ç¡®ä¿ `data/chinese/` ç›®å½•ä¸‹åŒ…å«å››å¤§åè‘—çš„æ–‡æœ¬æ–‡ä»¶ã€‚

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬è®­ç»ƒ

ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒï¼š
```bash
python train.py
```

ä½¿ç”¨é…ç½®æ–‡ä»¶è®­ç»ƒï¼š
```bash
python train.py config/train_shakespeare_char.py
```

### å‘½ä»¤è¡Œå‚æ•°è¦†ç›–

å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®ï¼š
```bash
python train.py config/train_shakespeare_char.py --batch_size=32 --learning_rate=1e-4
```

### é…ç½®æ–‡ä»¶æ ¼å¼

é…ç½®æ–‡ä»¶æ˜¯ Python æ–‡ä»¶ï¼ŒåŒ…å«è®­ç»ƒå‚æ•°ï¼š

```python
# è¾“å‡ºç›®å½•
out_dir = 'out-shakespeare-char'

# æ•°æ®é›†
dataset = 'shakespeare_char'
batch_size = 64
block_size = 256

# æ¨¡å‹é…ç½®
n_layer = 6
n_head = 6
n_embd = 384
dropout = 0.2

# è®­ç»ƒé…ç½®
learning_rate = 1e-3
max_iters = 5000
```

## ä¸»è¦é…ç½®å‚æ•°

### æ•°æ®é›†ç›¸å…³
- `dataset`: æ•°æ®é›†åç§°ï¼ˆå¯¹åº” `data/` ç›®å½•ä¸‹çš„æ–‡ä»¶å¤¹ï¼‰
- `batch_size`: æ‰¹æ¬¡å¤§å°
- `block_size`: ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆåºåˆ—é•¿åº¦ï¼‰

### æ¨¡å‹ç›¸å…³
- `n_layer`: Transformer å±‚æ•°
- `n_head`: æ³¨æ„åŠ›å¤´æ•°
- `n_embd`: åµŒå…¥ç»´åº¦
- `dropout`: Dropout æ¯”ç‡
- `bias`: æ˜¯å¦ä½¿ç”¨åç½®ï¼ˆé»˜è®¤ Falseï¼‰

### è®­ç»ƒç›¸å…³
- `learning_rate`: å­¦ä¹ ç‡
- `max_iters`: æœ€å¤§è®­ç»ƒè¿­ä»£æ¬¡æ•°
- `warmup_iters`: å­¦ä¹ ç‡é¢„çƒ­æ­¥æ•°
- `lr_decay_iters`: å­¦ä¹ ç‡è¡°å‡æ­¥æ•°
- `min_lr`: æœ€å°å­¦ä¹ ç‡
- `weight_decay`: æƒé‡è¡°å‡
- `beta1`, `beta2`: AdamW ä¼˜åŒ–å™¨çš„åŠ¨é‡å‚æ•°
- `grad_clip`: æ¢¯åº¦è£å‰ªé˜ˆå€¼

### ç³»ç»Ÿç›¸å…³
- `device`: è®¾å¤‡ç±»å‹ï¼ˆ'cuda' æˆ– 'cpu'ï¼‰
- `dtype`: æ•°æ®ç±»å‹ï¼ˆ'float32', 'bfloat16', 'float16'ï¼‰
- `compile`: æ˜¯å¦ä½¿ç”¨ PyTorch 2.0 ç¼–è¯‘ï¼ˆCPU æ¨¡å¼ä¸‹éœ€è¦ C++ ç¼–è¯‘å™¨ï¼‰

## æ³¨æ„äº‹é¡¹

### CPU è®­ç»ƒ
- åœ¨ CPU æ¨¡å¼ä¸‹ï¼Œ`torch.compile` ä¼šè‡ªåŠ¨ç¦ç”¨ï¼ˆéœ€è¦ C++ ç¼–è¯‘å™¨ï¼‰
- å¦‚éœ€å¯ç”¨ç¼–è¯‘ï¼Œè¯·å®‰è£… Visual Studio Build Toolsï¼ˆWindowsï¼‰æˆ– GCC/Clangï¼ˆLinux/Macï¼‰

### æ£€æŸ¥ç‚¹
- æ£€æŸ¥ç‚¹ä¿å­˜åœ¨ `out_dir` ç›®å½•ä¸‹
- ä½¿ç”¨ `init_from = 'resume'` å¯ä»¥ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ

### åˆ†å¸ƒå¼è®­ç»ƒ
- æ”¯æŒå¤š GPU åˆ†å¸ƒå¼è®­ç»ƒï¼ˆDDPï¼‰
- ä½¿ç”¨ç¯å¢ƒå˜é‡ `RANK`, `LOCAL_RANK`, `WORLD_SIZE` é…ç½®

## é¡¹ç›®ç»“æ„

```
nanoGPT/
â”œâ”€â”€ train.py              # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ model.py              # GPT æ¨¡å‹å®šä¹‰
â”œâ”€â”€ configurator.py       # é…ç½®è§£æå™¨
â”œâ”€â”€ sample.py             # Shakespeare æ–‡æœ¬ç”Ÿæˆè„šæœ¬
â”œâ”€â”€ sample_chinese.py     # ä¸­æ–‡æ–‡æœ¬ç”Ÿæˆè„šæœ¬
â”œâ”€â”€ requirements.txt      # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ config/               # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ train_shakespeare_char.py  # Shakespeare è®­ç»ƒé…ç½®
â”‚   â””â”€â”€ train_chinese.py           # ä¸­æ–‡å››å¤§åè‘—è®­ç»ƒé…ç½®
â”œâ”€â”€ data/                 # æ•°æ®é›†ç›®å½•
â”‚   â”œâ”€â”€ shakespeare_char/
â”‚   â”‚   â”œâ”€â”€ prepare.py    # æ•°æ®é¢„å¤„ç†è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ train.bin    # è®­ç»ƒæ•°æ®
â”‚   â”‚   â””â”€â”€ val.bin      # éªŒè¯æ•°æ®
â”‚   â””â”€â”€ chinese/
â”‚       â”œâ”€â”€ prepare.py    # ä¸­æ–‡æ•°æ®é¢„å¤„ç†è„šæœ¬
â”‚       â”œâ”€â”€ hongloumeng.txt    # çº¢æ¥¼æ¢¦
â”‚       â”œâ”€â”€ sanguoyanyi.txt    # ä¸‰å›½æ¼”ä¹‰
â”‚       â”œâ”€â”€ shuihuzhuan.txt    # æ°´æµ’ä¼ 
â”‚       â”œâ”€â”€ xiyouji.txt        # è¥¿æ¸¸è®°
â”‚       â”œâ”€â”€ train.bin    # è®­ç»ƒæ•°æ®
â”‚       â””â”€â”€ val.bin      # éªŒè¯æ•°æ®
â””â”€â”€ out/                  # è¾“å‡ºç›®å½•ï¼ˆè®­ç»ƒæ£€æŸ¥ç‚¹ï¼‰
    â”œâ”€â”€ out-shakespeare-char/  # Shakespeare æ¨¡å‹æ£€æŸ¥ç‚¹
    â””â”€â”€ out-chinese/           # ä¸­æ–‡æ¨¡å‹æ£€æŸ¥ç‚¹
```

## å¿«é€Ÿå¼€å§‹

### 1. Shakespeare å­—ç¬¦çº§æ¨¡å‹

#### æ•°æ®é¢„å¤„ç†
```bash
cd data/shakespeare_char
python prepare.py
cd ../..
```

#### è®­ç»ƒæ¨¡å‹
```bash
python train.py config/train_shakespeare_char.py
```

è®­ç»ƒå®Œæˆåï¼Œæ£€æŸ¥ç‚¹ä¼šä¿å­˜åœ¨ `out-shakespeare-char/ckpt.pt`ã€‚

#### ç”Ÿæˆæ–‡æœ¬
```bash
# æ–¹å¼1ï¼šé€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®š out_dir
python sample.py --out_dir=out-shakespeare-char

# æ–¹å¼2ï¼šä¿®æ”¹ sample.py ä¸­çš„å‚æ•°
# ç¼–è¾‘ sample.pyï¼Œè®¾ç½®ï¼š
# out_dir = 'out-shakespeare-char'
# ç„¶åè¿è¡Œï¼š
python sample.py
```

å¯ä»¥åŒæ—¶ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–å…¶ä»–å‚æ•°ï¼š
```bash
python sample.py --out_dir=out-shakespeare-char --start="ROMEO:" --num_samples=5 --temperature=0.9
```

æˆ–è€…ä¿®æ”¹ `sample.py` ä¸­çš„å‚æ•°ï¼š
```python
init_from = 'resume'
out_dir = 'out-shakespeare-char'  # æŒ‡å®šæ£€æŸ¥ç‚¹ç›®å½•
start = '\n'  # èµ·å§‹æç¤ºè¯
num_samples = 10  # ç”Ÿæˆæ ·æœ¬æ•°é‡
max_new_tokens = 500  # æœ€å¤§ç”Ÿæˆé•¿åº¦
temperature = 0.8  # é‡‡æ ·æ¸©åº¦
top_k = 200  # Top-k é‡‡æ ·
```

### 2. å››å¤§åè‘—ä¸­æ–‡æ¨¡å‹

#### æ•°æ®é¢„å¤„ç†
é¦–å…ˆç¡®ä¿ `data/chinese/` ç›®å½•ä¸‹æœ‰ä»¥ä¸‹æ–‡ä»¶ï¼š
- `hongloumeng.txt` (çº¢æ¥¼æ¢¦)
- `sanguoyanyi.txt` (ä¸‰å›½æ¼”ä¹‰)
- `shuihuzhuan.txt` (æ°´æµ’ä¼ )
- `xiyouji.txt` (è¥¿æ¸¸è®°)

ç„¶åè¿è¡Œé¢„å¤„ç†è„šæœ¬ï¼š
```bash
cd data/chinese
python prepare.py
cd ../..
```

è¿™ä¼šç”Ÿæˆï¼š
- `train.bin` - è®­ç»ƒæ•°æ®
- `val.bin` - éªŒè¯æ•°æ®
- `meta.pkl` - å­—ç¬¦ç¼–ç æ˜ å°„

#### è®­ç»ƒæ¨¡å‹
```bash
python train.py config/train_chinese.py
```

è®­ç»ƒé…ç½®ï¼ˆé’ˆå¯¹ RTX 3060 ä¼˜åŒ–ï¼‰ï¼š
- `batch_size = 32` - å……åˆ†åˆ©ç”¨ 12GB æ˜¾å­˜
- `block_size = 512` - é€‚åˆä¸­æ–‡æ–‡æœ¬çš„ä¸Šä¸‹æ–‡é•¿åº¦
- `n_layer = 12, n_head = 12, n_embd = 768` - ä¸­ç­‰è§„æ¨¡æ¨¡å‹
- `max_iters = 5000` - è®­ç»ƒæ­¥æ•°ï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰

è®­ç»ƒå®Œæˆåï¼Œæ£€æŸ¥ç‚¹ä¼šä¿å­˜åœ¨ `out-chinese/ckpt.pt`ã€‚

#### ç”Ÿæˆæ–‡æœ¬
```bash
# æ–¹å¼1ï¼šé€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®š out_dir
python sample_chinese.py --out_dir=out-chinese

# æ–¹å¼2ï¼šä¿®æ”¹ sample_chinese.py ä¸­çš„å‚æ•°
# ç¼–è¾‘ sample_chinese.pyï¼Œè®¾ç½®ï¼š
# out_dir = 'out-chinese'
# ç„¶åè¿è¡Œï¼š
python sample_chinese.py
```

å¯ä»¥åŒæ—¶ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–å…¶ä»–å‚æ•°ï¼š
```bash
python sample_chinese.py --out_dir=out-chinese --start="è¯è¯´" --num_samples=3 --temperature=0.7
```

æˆ–è€…ä¿®æ”¹ `sample_chinese.py` ä¸­çš„å‚æ•°ï¼š
```python
init_from = 'resume'
out_dir = 'out-chinese'  # æŒ‡å®šæ£€æŸ¥ç‚¹ç›®å½•
start = '\n'  # èµ·å§‹æç¤ºè¯ï¼Œä¾‹å¦‚ï¼š'è¯è¯´'ã€'å´è¯´'ã€'ä¸”è¯´' ç­‰
num_samples = 5  # ç”Ÿæˆæ ·æœ¬æ•°é‡
max_new_tokens = 500  # æœ€å¤§ç”Ÿæˆé•¿åº¦
temperature = 0.8  # é‡‡æ ·æ¸©åº¦ï¼ˆè¶Šä½è¶Šç¡®å®šï¼‰
top_k = 200  # Top-k é‡‡æ ·
```

### 3. ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ

å¦‚æœè®­ç»ƒä¸­æ–­ï¼Œå¯ä»¥ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼š
```bash
# ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„ init_from
# init_from = 'resume'  # æ”¹ä¸º 'resume'

# ç„¶åé‡æ–°è¿è¡Œè®­ç»ƒ
python train.py config/train_chinese.py
```

## ç¤ºä¾‹

è®­ç»ƒ Shakespeare å­—ç¬¦çº§æ¨¡å‹ï¼š
```bash
python train.py config/train_shakespeare_char.py
```

è®­ç»ƒå®Œæˆåï¼Œæ£€æŸ¥ç‚¹ä¼šä¿å­˜åœ¨ `out-shakespeare-char/ckpt.pt`ã€‚

## è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æºã€‚
